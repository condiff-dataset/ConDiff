{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b1ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3fba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8470633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import optax\n",
    "import equinox as eqx\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "from functools import partial\n",
    "from jax.lax import scan, dot_general\n",
    "from load_ConDiff import load_ConDiff\n",
    "from architectures import DilResNet, FFNO\n",
    "from jax import config, random, grad, vmap, jit\n",
    "from jax.tree_util import tree_map, tree_flatten\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "995b18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relative_error(model, features, targets, coordinates, n):\n",
    "    prediction = vmap(model, in_axes=(0, None))(features[n], coordinates)\n",
    "    relative_error = jnp.linalg.norm((prediction - targets[n]).reshape(n.size, -1), axis=1) / jnp.linalg.norm(targets[n].reshape(n.size, -1), axis=1)\n",
    "    return relative_error\n",
    "\n",
    "def train_on_epoch(key, batch_size, model, features, coordinates, targets, opt_state, make_step):\n",
    "    N_samples = len(features)\n",
    "    list_of_indices = jnp.linspace(0, N_samples-1, N_samples, dtype=jnp.int64)\n",
    "    n_batches = N_samples // batch_size\n",
    "    carry = [model, features, coordinates, targets, opt_state]\n",
    "    n = random.choice(key, list_of_indices, shape = (n_batches, batch_size))\n",
    "    data, epoch_loss = scan(make_step, carry, n)\n",
    "    model = data[0]\n",
    "    opt_state = data[4]\n",
    "    return epoch_loss, model, opt_state\n",
    "\n",
    "def test_on_epoch(key, batch_size, model, features, coordinates, targets):\n",
    "    N_samples_test = len(features)\n",
    "    list_of_indices_test = jnp.linspace(0, N_samples_test-1, N_samples_test, dtype=jnp.int64)\n",
    "    n_batches_test = N_samples_test // batch_size\n",
    "    n_test = random.choice(key, list_of_indices_test, shape = (n_batches_test, batch_size))\n",
    "    loss_test_error = lambda a, ind: (None, FFNO.compute_loss(model, features[ind], coordinates, targets[ind]))\n",
    "    _, test_loss = scan(loss_test_error, None, n_test)\n",
    "    return jnp.mean(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0977be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FFNO(key, coordinates, features, grid):\n",
    "    input = features[0]\n",
    "    D = len(input.shape[1:])\n",
    "    \n",
    "    N_modes = 12\n",
    "    N_features_out = 1\n",
    "    \n",
    "    if grid <= 64:\n",
    "        N_features_ = 48\n",
    "    else:\n",
    "        N_features_ = grid // 4\n",
    "    N_layers = 4\n",
    "    N_features = [coordinates.shape[0] + features.shape[1], N_features_, N_features_out]\n",
    "    \n",
    "    model = FFNO.FFNO(N_layers, N_features, N_modes, key, D)\n",
    "    \n",
    "    N_epoch = 400\n",
    "    \n",
    "    if grid <= 64:\n",
    "        batch_size = 4\n",
    "    else:\n",
    "        batch_size = 16\n",
    "        \n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    model_data = {\n",
    "        \"model\": model\n",
    "    }\n",
    "    \n",
    "    optimization_specification = {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"compute_loss\": FFNO.compute_loss,\n",
    "        \"make_step\": FFNO.make_step,\n",
    "        \"N_epochs\": N_epoch,\n",
    "        \"batch_size\": batch_size\n",
    "    }\n",
    "    return model_data, optimization_specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3551e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_data, features, coordinates, targets, optimization_specification):\n",
    "    model = model_data['model']\n",
    "    \n",
    "    history_train = []\n",
    "    history_test = []\n",
    "    \n",
    "    features_train, features_test = features[0], features[1]\n",
    "    targets_train, targets_test = targets[0], targets[1]\n",
    "\n",
    "    c = features_train.shape[0] // optimization_specification['batch_size']\n",
    "    keys = tree_map(lambda x: x * c, np.arange(50, 1000, 50))\n",
    "    values = [0.5, ] * len(keys)\n",
    "    dict_lr = dict(zip(keys, values))\n",
    "\n",
    "    sc = optax.piecewise_constant_schedule(optimization_specification['learning_rate'], dict_lr)\n",
    "    optimizer = optax.adamw(sc, weight_decay=1e-2)\n",
    "    opt_state = optimizer.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "    make_step = lambda x, y: optimization_specification['make_step'](x, y, optimizer)\n",
    "\n",
    "    for it in tqdm(range(optimization_specification['N_epochs'])):\n",
    "        key = random.PRNGKey(it)\n",
    "        loss, model, opt_state = train_on_epoch(key, optimization_specification['batch_size'], model, features_train, coordinates, targets_train, opt_state, make_step)\n",
    "        history_train.append(jnp.mean(loss))\n",
    "\n",
    "        test_loss = test_on_epoch(key, optimization_specification['batch_size'], model, features_test, coordinates, targets_test)\n",
    "        history_test.append(test_loss)\n",
    "\n",
    "    return model, history_train, history_test\n",
    "\n",
    "def get_datasets(direction_to_save, type_of_pde, grid):\n",
    "    train_dataset, test_dataset = load_ConDiff(save_dir=direction_to_save, \n",
    "                                               pde=type_of_pde, \n",
    "                                               grid=grid)\n",
    "    \n",
    "    x = jnp.linspace(0, 1, grid)\n",
    "    y = jnp.linspace(0, 1, grid)\n",
    "    x_, y_ = jnp.meshgrid(x, y)\n",
    "    coordinates = jnp.stack([x_, y_], 0)\n",
    "    \n",
    "    features_train = tree_map(lambda x: x.reshape(-1, grid, grid), train_dataset[0])\n",
    "    targets_train = tree_map(lambda x: x.reshape(-1, grid, grid), train_dataset[1])\n",
    "    \n",
    "    features_test = tree_map(lambda x: x.reshape(-1, grid, grid), test_dataset[0])\n",
    "    targets_test = tree_map(lambda x: x.reshape(-1, grid, grid), test_dataset[1])\n",
    "    \n",
    "    return [jnp.expand_dims(features_train, 1), jnp.expand_dims(targets_train, 1)], \\\n",
    "           [jnp.expand_dims(features_test, 1), jnp.expand_dims(targets_test, 1)], coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9df99798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(key, direction_to_save, type_of_pde, grid):\n",
    "    keys = random.split(key, 3)\n",
    "    \n",
    "    train_dataset, test_dataset, coordinates = get_datasets(direction_to_save, type_of_pde, grid)\n",
    "    features_train, targets_train = train_dataset[0], train_dataset[1]\n",
    "    features_test, targets_test = test_dataset[0], test_dataset[1]\n",
    "    \n",
    "    model_data, optimization_specification = get_FFNO(keys[0], coordinates, features_train, grid)\n",
    "    model, history_train, history_test = train_model(model_data, features, coordinates, targets, \n",
    "                                                     optimization_specification=optimization_specification)\n",
    "    \n",
    "    N_samples_train = features_train.shape[0]\n",
    "    list_of_indices_train = jnp.linspace(0, N_samples_train-1, N_samples_train, dtype=jnp.int64)\n",
    "    n_batches_train = N_samples_train // optimization_specification['batch_size']\n",
    "    n_train = random.choice(keys[1], list_of_indices_train, shape = (n_batches_train, optimization_specification['batch_size']))\n",
    "    \n",
    "    N_samples_test = features_test.shape[0]\n",
    "    list_of_indices_test = jnp.linspace(0, N_samples_test-1, N_samples_test, dtype=jnp.int64)\n",
    "    n_batches_test = N_samples_test // optimization_specification['batch_size']\n",
    "    n_test = random.choice(keys[2], list_of_indices_test, shape = (n_batches_test, optimization_specification['batch_size']))\n",
    "    \n",
    "    loss_train_error = lambda a, x: (None, compute_relative_error(model, features_train, targets_train, coordinates, x))\n",
    "    _, train_loss_error = scan(loss_train_error, None, n_train)\n",
    "    train_error_mean = jnp.mean(train_loss_error.reshape(-1,))\n",
    "\n",
    "    loss_test_error = lambda a, x: (None, compute_relative_error(model, features_test, targets_test, coordinates, x))\n",
    "    _, test_loss_error = scan(loss_test_error, None, n_test)\n",
    "    test_error_mean = jnp.mean(test_loss_error.reshape(-1,))\n",
    "\n",
    "    train_error_std = jnp.sqrt(jnp.var(test_loss_error.reshape(-1,)))\n",
    "    test_error_std = jnp.sqrt(jnp.var(test_loss_error.reshape(-1,)))\n",
    "\n",
    "    model_size = sum(tree_map(jnp.size, tree_flatten(model)[0], is_leaf=eqx.is_array))\n",
    "    \n",
    "    data = {\n",
    "        'history_train': history_train,\n",
    "        'history_test': history_test,\n",
    "        'train_error_mean': train_error_mean,\n",
    "        'test_error_mean': test_error_mean,\n",
    "        'train_error_std': train_error_std,\n",
    "        'test_error_std': test_error_std,\n",
    "        'model_size': model_size\n",
    "    }\n",
    "    return data, model, model_data, features_test, targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733dd03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_data, features, coordinates, targets, optimization_specification):\n",
    "    model = model_data['model']\n",
    "    \n",
    "    history_train = []\n",
    "    history_test = []\n",
    "    \n",
    "    features_train, features_test = features[0], features[1]\n",
    "    targets_train, targets_test = targets[0], targets[1]\n",
    "\n",
    "    c = features_train.shape[0] // optimization_specification['batch_size']\n",
    "    keys = tree_map(lambda x: x * c, np.arange(50, 1000, 50))\n",
    "    values = [0.5, ] * len(keys)\n",
    "    dict_lr = dict(zip(keys, values))\n",
    "\n",
    "    sc = optax.piecewise_constant_schedule(optimization_specification['learning_rate'], dict_lr)\n",
    "    optimizer = optax.adamw(sc, weight_decay=1e-2)\n",
    "    opt_state = optimizer.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "    make_step = lambda x, y: optimization_specification['make_step'](x, y, optimizer)\n",
    "\n",
    "    for it in tqdm(range(optimization_specification['N_epochs'])):\n",
    "        key = random.PRNGKey(it)\n",
    "        loss, model, opt_state = train_on_epoch(key, optimization_specification['batch_size'], model, features_train, coordinates, targets_train, opt_state, make_step)\n",
    "        history_train.append(jnp.mean(loss))\n",
    "\n",
    "        test_loss = test_on_epoch(key, optimization_specification['batch_size'], model, features_test, coordinates, targets_test)\n",
    "        history_test.append(test_loss)\n",
    "    return model, history_train, history_test\n",
    "\n",
    "def get_datasets(direction_to_save, type_of_pde, grid):\n",
    "    train_dataset, test_dataset = load_ConDiff(save_dir=direction_to_save, \n",
    "                                               pde=type_of_pde, \n",
    "                                               grid=grid)\n",
    "    x = jnp.linspace(0, 1, grid)\n",
    "    y = jnp.linspace(0, 1, grid)\n",
    "    xx, yy = jnp.meshgrid(x, y)\n",
    "    coordinates = jnp.stack([xx, yy], 0)\n",
    "    \n",
    "    features_train = tree_map(lambda x: x.reshape(-1, grid, grid), train_dataset[0])\n",
    "    targets_train = tree_map(lambda x: x.reshape(-1, grid, grid), train_dataset[1])\n",
    "    \n",
    "    features_test = tree_map(lambda x: x.reshape(-1, grid, grid), test_dataset[0])\n",
    "    targets_test = tree_map(lambda x: x.reshape(-1, grid, grid), test_dataset[1])\n",
    "    \n",
    "    return [jnp.expand_dims(features_train, 1), jnp.expand_dims(targets_train, 1)], \\\n",
    "           [jnp.expand_dims(features_test, 1), jnp.expand_dims(targets_test, 1)], coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31a5c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(key, direction_to_save, type_of_pde, grid):\n",
    "    keys = random.split(key, 3)\n",
    "    \n",
    "    train_dataset, test_dataset, coordinates = get_datasets(direction_to_save, type_of_pde, grid)\n",
    "    features_train, targets_train = train_dataset[0], train_dataset[1]\n",
    "    features_test, targets_test = test_dataset[0], test_dataset[1]\n",
    "\n",
    "    model_data, optimization_specification = get_FFNO(keys[0], coordinates, features_train, grid)\n",
    "    \n",
    "    features = [features_train, features_test]\n",
    "    targets = [targets_train, targets_test]\n",
    "    \n",
    "    model, history_train, history_test = train_model(model_data, features, coordinates, targets, \n",
    "                                                 optimization_specification=optimization_specification)\n",
    "    \n",
    "    N_samples_train = features_train.shape[0]\n",
    "    list_of_indices_train = jnp.linspace(0, N_samples_train-1, N_samples_train, dtype=jnp.int64)\n",
    "    n_batches_train = N_samples_train // optimization_specification['batch_size']\n",
    "    n_train = random.choice(keys[1], list_of_indices_train, shape = (n_batches_train, optimization_specification['batch_size']))\n",
    "    \n",
    "    N_samples_test = features_test.shape[0]\n",
    "    list_of_indices_test = jnp.linspace(0, N_samples_test-1, N_samples_test, dtype=jnp.int64)\n",
    "    n_batches_test = N_samples_test // optimization_specification['batch_size']\n",
    "    n_test = random.choice(keys[2], list_of_indices_test, shape = (n_batches_test, optimization_specification['batch_size']))\n",
    "    \n",
    "    loss_train_error = lambda a, x: (None, compute_relative_error(model, features_train, targets_train, coordinates, x))\n",
    "    _, train_loss_error = scan(loss_train_error, None, n_train)\n",
    "    train_error_mean = jnp.mean(train_loss_error.reshape(-1,))\n",
    "    \n",
    "    loss_test_error = lambda a, x: (None, compute_relative_error(model, features_test, targets_test, coordinates, x))\n",
    "    _, test_loss_error = scan(loss_test_error, None, n_test)\n",
    "    test_error_mean = jnp.mean(test_loss_error.reshape(-1,))\n",
    "\n",
    "    train_error_std = jnp.sqrt(jnp.var(test_loss_error.reshape(-1,)))\n",
    "    test_error_std = jnp.sqrt(jnp.var(test_loss_error.reshape(-1,)))\n",
    "\n",
    "    model_size = sum(tree_map(jnp.size, tree_flatten(model)[0], is_leaf=eqx.is_array))\n",
    "    \n",
    "    data = {\n",
    "        'history_train': history_train,\n",
    "        'history_test': history_test,\n",
    "        'train_error_mean': train_error_mean,\n",
    "        'test_error_mean': test_error_mean,\n",
    "        'train_error_std': train_error_std,\n",
    "        'test_error_std': test_error_std,\n",
    "        'model_size': model_size\n",
    "    }\n",
    "    return data, model, model_data, features_test, targets_test, coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6113ffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 17:50:58.978304: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.4 which is older than the ptxas CUDA version (12.5.40). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 398/400 [14:53<00:04,  2.22s/it]"
     ]
    }
   ],
   "source": [
    "key = random.PRNGKey(22)\n",
    "\n",
    "grid = 64\n",
    "type_of_pde = 'poisson'\n",
    "direction_to_save = \n",
    "\n",
    "data, model, model_data, features_test, targets_test, coordinates = get_results(key, direction_to_save, type_of_pde, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b3cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model, model_data, data, features_test, targets_test, coordinates):\n",
    "    prediction = vmap(lambda x, coords: model(x, coords), in_axes=(0, None))(features_test, coordinates)[:, 0]\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    fig, ax = plt.subplots(1, len(prediction[0].shape)+1, figsize=((len(prediction[0].shape)+1)*5, 4))\n",
    "\n",
    "    ax[0].set_title(r'Loss', fontsize=\"15\")\n",
    "    ax[0].set_yscale('log')\n",
    "    ax[0].set_xlabel(r'# its.')\n",
    "    ax[0].plot(data['history_train'], linestyle='-', color='red', label='train')\n",
    "    ax[0].plot(data['history_test'], linestyle='-.', color='green', label='test')\n",
    "    ax[0].legend(loc='best', fontsize=\"12\")\n",
    "    ax[0].spines['top'].set_visible(False)\n",
    "    ax[0].spines['left'].set_visible(True)\n",
    "    ax[0].spines['right'].set_visible(False)\n",
    "    ax[0].grid(linestyle='-.')\n",
    "\n",
    "    ax[1].contourf(prediction[0])\n",
    "    ax[1].set_title(r'Prediction')\n",
    "\n",
    "    ax[2].contourf(targets_test[0, 0])\n",
    "    ax[2].set_title(r'Target')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca21d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(model, model_data, data, features_test, targets_test, coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469e87fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = data['model_size']\n",
    "train_error_mean = jnp.round(data['train_error_mean'], 3)\n",
    "test_error_mean = jnp.round(data['test_error_mean'], 3)\n",
    "train_error_std = jnp.round(data['train_error_std'], 3)\n",
    "test_error_std = jnp.round(data['test_error_std'], 3)\n",
    "\n",
    "print(f'Model size: {model_size}')\n",
    "print(f\"Train relative error: {train_error_mean} ± {train_error_std}, \\nTest relative error: {test_error_mean} ± {test_error_std}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
